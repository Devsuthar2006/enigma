<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Interview Session ‚Äî DebAItor</title>
  <meta name="description" content="Live AI Interview session with voice-first interaction.">
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
  <style>
    *, *::before, *::after { box-sizing: border-box; margin: 0; padding: 0; }

    :root {
      --bg: #0a0a0f;
      --surface: #12121a;
      --border: rgba(255,255,255,0.06);
      --text-primary: #f1f5f9;
      --text-secondary: #94a3b8;
      --text-muted: #475569;
      --accent: #0ea5e9;
      --accent-glow: rgba(14, 165, 233, 0.15);
      --danger: #ef4444;
      --font: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
    }

    body {
      background: var(--bg);
      color: var(--text-primary);
      font-family: var(--font);
      min-height: 100vh;
      display: flex;
      flex-direction: column;
      overflow: hidden;
    }

    /* ‚îÄ‚îÄ Top Bar ‚îÄ‚îÄ */
    .topbar {
      display: flex;
      align-items: center;
      justify-content: space-between;
      padding: 1rem 1.5rem;
      border-bottom: 1px solid var(--border);
      flex-shrink: 0;
    }
    .topbar-left {
      display: flex;
      align-items: center;
      gap: 0.75rem;
    }
    .topbar-logo {
      font-size: 0.85rem;
      font-weight: 700;
      letter-spacing: -0.02em;
      color: var(--text-secondary);
    }
    .topbar-logo span { color: var(--accent); }
    .topbar-badge {
      font-size: 0.65rem;
      font-weight: 600;
      text-transform: uppercase;
      letter-spacing: 0.08em;
      background: var(--accent-glow);
      color: var(--accent);
      padding: 0.25rem 0.6rem;
      border-radius: 20px;
      border: 1px solid rgba(14,165,233,0.2);
    }
    .topbar-right {
      display: flex;
      align-items: center;
      gap: 1rem;
    }
    .topbar-meta {
      font-size: 0.75rem;
      color: var(--text-muted);
      text-align: right;
    }
    .topbar-meta strong {
      color: var(--text-secondary);
      font-weight: 600;
    }
    .btn-end {
      font-size: 0.75rem;
      font-weight: 600;
      color: var(--danger);
      background: rgba(239,68,68,0.1);
      border: 1px solid rgba(239,68,68,0.2);
      padding: 0.4rem 0.85rem;
      border-radius: 6px;
      cursor: pointer;
      transition: all 0.15s;
      font-family: var(--font);
    }
    .btn-end:hover { background: rgba(239,68,68,0.2); }

    /* ‚îÄ‚îÄ Main Content Area ‚îÄ‚îÄ */
    .session-body {
      flex: 1;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      padding: 2rem 1.5rem;
      position: relative;
      overflow-y: auto;
    }

    /* ‚îÄ‚îÄ AI Question Display ‚îÄ‚îÄ */
    .ai-question-area {
      text-align: center;
      max-width: 640px;
      width: 100%;
      margin-bottom: 2rem;
    }
    .ai-label {
      font-size: 0.7rem;
      font-weight: 600;
      text-transform: uppercase;
      letter-spacing: 0.1em;
      color: var(--accent);
      margin-bottom: 1rem;
      display: flex;
      align-items: center;
      justify-content: center;
      gap: 0.5rem;
    }
    .ai-label .dot {
      width: 6px;
      height: 6px;
      border-radius: 50%;
      background: var(--accent);
      animation: pulse-dot 2s ease-in-out infinite;
    }
    @keyframes pulse-dot {
      0%, 100% { opacity: 1; }
      50% { opacity: 0.3; }
    }

    .ai-question-text {
      font-size: 1.5rem;
      font-weight: 500;
      line-height: 1.5;
      color: var(--text-primary);
      letter-spacing: -0.01em;
      min-height: 3rem;
    }
    .ai-question-text.fade-in {
      animation: fadeInUp 0.6s ease-out forwards;
    }
    @keyframes fadeInUp {
      from { opacity: 0; transform: translateY(12px); }
      to { opacity: 1; transform: translateY(0); }
    }

    /* Typewriter cursor */
    .typewriter-cursor {
      display: inline-block;
      width: 2px;
      height: 1.2em;
      background: var(--accent);
      margin-left: 2px;
      vertical-align: text-bottom;
      animation: blink-cursor 0.8s step-end infinite;
    }
    @keyframes blink-cursor {
      0%, 100% { opacity: 1; }
      50% { opacity: 0; }
    }

    /* ‚îÄ‚îÄ Transcription Area ‚îÄ‚îÄ */
    .transcription-area {
      text-align: center;
      max-width: 560px;
      width: 100%;
      min-height: 2.5rem;
      margin-bottom: 2rem;
    }
    .transcription-label {
      font-size: 0.65rem;
      font-weight: 600;
      text-transform: uppercase;
      letter-spacing: 0.1em;
      color: var(--text-muted);
      margin-bottom: 0.75rem;
    }
    .transcription-text {
      font-size: 1.1rem;
      font-weight: 400;
      line-height: 1.6;
      color: var(--text-secondary);
      font-style: italic;
    }
    .transcription-text .word {
      display: inline;
      animation: wordFadeIn 0.3s ease-out forwards;
    }
    @keyframes wordFadeIn {
      from { opacity: 0; transform: translateY(4px); }
      to { opacity: 1; transform: translateY(0); }
    }

    /* ‚îÄ‚îÄ Status Indicator ‚îÄ‚îÄ */
    .status-indicator {
      text-align: center;
      margin-bottom: 1.5rem;
      min-height: 1.5rem;
    }
    .status-text {
      font-size: 0.8rem;
      font-weight: 500;
      color: var(--text-muted);
      display: inline-flex;
      align-items: center;
      gap: 0.5rem;
    }
    .status-text.listening { color: var(--accent); }
    .status-text.processing { color: #f59e0b; }

    .listening-dots span {
      display: inline-block;
      width: 4px;
      height: 4px;
      border-radius: 50%;
      background: currentColor;
      animation: dotBounce 1.4s ease-in-out infinite;
    }
    .listening-dots span:nth-child(2) { animation-delay: 0.2s; }
    .listening-dots span:nth-child(3) { animation-delay: 0.4s; }
    @keyframes dotBounce {
      0%, 80%, 100% { transform: scale(0.6); opacity: 0.4; }
      40% { transform: scale(1); opacity: 1; }
    }

    /* ‚îÄ‚îÄ Waveform Canvas ‚îÄ‚îÄ */
    .waveform-container {
      width: 100%;
      max-width: 280px;
      height: 48px;
      margin: 0 auto 1.5rem;
      display: none;
    }
    .waveform-container.active { display: block; }
    .waveform-container canvas {
      width: 100%;
      height: 100%;
      border-radius: 8px;
    }

    /* ‚îÄ‚îÄ Microphone Button ‚îÄ‚îÄ */
    .mic-area {
      display: flex;
      flex-direction: column;
      align-items: center;
      gap: 1rem;
      flex-shrink: 0;
      padding-bottom: 1rem;
    }
    .mic-btn {
      width: 80px;
      height: 80px;
      border-radius: 50%;
      border: none;
      cursor: pointer;
      display: flex;
      align-items: center;
      justify-content: center;
      background: var(--surface);
      border: 2px solid var(--border);
      transition: all 0.3s ease;
      position: relative;
    }
    .mic-btn svg {
      width: 28px;
      height: 28px;
      fill: var(--text-secondary);
      transition: fill 0.3s;
    }
    .mic-btn:hover {
      border-color: var(--accent);
      background: rgba(14, 165, 233, 0.05);
    }
    .mic-btn:hover svg { fill: var(--accent); }

    /* Active / Recording state */
    .mic-btn.recording {
      background: rgba(239, 68, 68, 0.1);
      border-color: var(--danger);
      animation: mic-pulse 2s ease-in-out infinite;
    }
    .mic-btn.recording svg { fill: var(--danger); }
    @keyframes mic-pulse {
      0%, 100% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.3); }
      50% { box-shadow: 0 0 0 16px rgba(239, 68, 68, 0); }
    }

    /* Ring animation */
    .mic-btn::before {
      content: '';
      position: absolute;
      width: 100%;
      height: 100%;
      border-radius: 50%;
      border: 2px solid var(--accent);
      opacity: 0;
      transition: all 0.3s;
    }
    .mic-btn.recording::before {
      border-color: var(--danger);
      animation: ring-expand 1.5s ease-out infinite;
    }
    @keyframes ring-expand {
      0% { width: 100%; height: 100%; opacity: 0.6; }
      100% { width: 140%; height: 140%; opacity: 0; }
    }

    /* ‚îÄ‚îÄ Fallback Text Mode ‚îÄ‚îÄ */
    .text-mode-toggle {
      font-size: 0.72rem;
      color: var(--text-muted);
      text-decoration: none;
      cursor: pointer;
      border: none;
      background: none;
      font-family: var(--font);
      transition: color 0.15s;
      padding: 0.25rem;
    }
    .text-mode-toggle:hover { color: var(--text-secondary); }

    /* ‚îÄ‚îÄ Text Mode Input (hidden by default) ‚îÄ‚îÄ */
    .text-input-area {
      display: none;
      width: 100%;
      max-width: 560px;
      margin: 0 auto;
    }
    .text-input-area.visible { display: flex; gap: 0.5rem; }
    .text-input-area input {
      flex: 1;
      padding: 0.85rem 1rem;
      background: var(--surface);
      border: 1px solid var(--border);
      border-radius: 8px;
      color: var(--text-primary);
      font-size: 0.95rem;
      font-family: var(--font);
      outline: none;
      transition: border-color 0.15s;
    }
    .text-input-area input:focus { border-color: var(--accent); }
    .text-input-area button {
      padding: 0.85rem 1.25rem;
      background: var(--accent);
      color: #fff;
      border: none;
      border-radius: 8px;
      font-size: 0.85rem;
      font-weight: 600;
      cursor: pointer;
      font-family: var(--font);
      transition: filter 0.15s;
    }
    .text-input-area button:hover { filter: brightness(1.15); }

    /* ‚îÄ‚îÄ Question Counter ‚îÄ‚îÄ */
    .question-counter {
      font-size: 0.7rem;
      color: var(--text-muted);
      margin-top: 0.5rem;
    }

    /* ‚îÄ‚îÄ Mute Toggle ‚îÄ‚îÄ */
    .btn-mute {
      font-size: 0.8rem;
      background: none;
      border: 1px solid var(--border);
      color: var(--text-secondary);
      padding: 0.35rem 0.65rem;
      border-radius: 6px;
      cursor: pointer;
      font-family: var(--font);
      transition: all 0.15s;
      display: inline-flex;
      align-items: center;
      gap: 0.3rem;
    }
    .btn-mute:hover { border-color: var(--accent); color: var(--accent); }
    .btn-mute.muted { color: var(--danger); border-color: rgba(239,68,68,0.3); }

    /* ‚îÄ‚îÄ TTS Loading Indicator ‚îÄ‚îÄ */
    .tts-indicator {
      display: none;
      align-items: center;
      justify-content: center;
      gap: 0.5rem;
      font-size: 0.72rem;
      font-weight: 500;
      color: var(--text-muted);
      margin-top: 0.75rem;
    }
    .tts-indicator.active { display: flex; }
    .tts-indicator .tts-spinner {
      width: 12px;
      height: 12px;
      border: 2px solid var(--border);
      border-top-color: var(--accent);
      border-radius: 50%;
      animation: spin 0.6s linear infinite;
    }
    @keyframes spin {
      to { transform: rotate(360deg); }
    }

    /* ‚îÄ‚îÄ Responsive ‚îÄ‚îÄ */
    @media (max-width: 640px) {
      .topbar { padding: 0.75rem 1rem; }
      .topbar-meta { display: none; }
      .ai-question-text { font-size: 1.2rem; }
      .session-body { padding: 1.5rem 1rem; }
      .mic-btn { width: 72px; height: 72px; }
      .mic-btn svg { width: 24px; height: 24px; }
    }

    /* Tap to begin overlay */
    .start-overlay {
      position: fixed;
      inset: 0;
      background: rgba(10,10,15,0.95);
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      z-index: 999;
      cursor: pointer;
      gap: 1rem;
      transition: opacity 0.4s;
    }
    .start-overlay.hidden {
      opacity: 0;
      pointer-events: none;
    }
    .start-overlay .start-icon {
      font-size: 3rem;
      animation: pulse-glow 2s ease-in-out infinite;
    }
    .start-overlay .start-text {
      font-size: 1.1rem;
      font-weight: 600;
      color: #94a3b8;
    }
    .start-overlay .start-sub {
      font-size: 0.75rem;
      color: #475569;
    }
    @keyframes pulse-glow {
      0%, 100% { transform: scale(1); opacity: 0.8; }
      50% { transform: scale(1.1); opacity: 1; }
    }
  </style>
</head>
<body>

  <!-- Tap to begin overlay -->
  <div class="start-overlay" id="start-overlay">
    <div class="start-icon">üé§</div>
    <div class="start-text">Tap to Begin Interview</div>
    <div class="start-sub">Enables voice playback</div>
  </div>

  <!-- ‚ïê‚ïê‚ïê Top Bar ‚ïê‚ïê‚ïê -->
  <header class="topbar">
    <div class="topbar-left">
      <div class="topbar-logo">DEBAITOR<span>.</span></div>
      <div class="topbar-badge">AI Interview</div>
    </div>
    <div class="topbar-right">
      <div class="topbar-meta" id="topbar-meta">
        <div><strong id="meta-role">Loading...</strong></div>
        <div id="meta-focus">‚Äî</div>
      </div>
      <button class="btn-mute" id="btn-mute" onclick="toggleMute()">üîä Voice</button>
      <button class="btn-end" onclick="endInterview()">End</button>
    </div>
  </header>

  <!-- ‚ïê‚ïê‚ïê Session Body ‚ïê‚ïê‚ïê -->
  <main class="session-body">
    <!-- AI Question Display -->
    <div class="ai-question-area">
      <div class="ai-label">
        <span class="dot"></span>
        AI INTERVIEWER
      </div>
      <div class="ai-question-text fade-in" id="ai-question">
        Welcome! I'll be conducting your interview today. When you're ready, tap the microphone to introduce yourself.
      </div>
      <div class="tts-indicator" id="tts-indicator">
        <div class="tts-spinner"></div>
        <span>Generating voice...</span>
      </div>
    </div>

    <!-- Live Transcription -->
    <div class="transcription-area" id="transcription-area" style="display:none;">
      <div class="transcription-label">YOUR ANSWER</div>
      <div class="transcription-text" id="transcription-text"></div>
    </div>

    <!-- Status Indicator -->
    <div class="status-indicator">
      <div class="status-text" id="status-text">Tap the mic to begin</div>
    </div>

    <!-- Waveform -->
    <div class="waveform-container" id="waveform-container">
      <canvas id="waveform-canvas"></canvas>
    </div>
  </main>

  <!-- ‚ïê‚ïê‚ïê Mic Area (Fixed Bottom) ‚ïê‚ïê‚ïê -->
  <footer class="mic-area">
    <button class="mic-btn" id="mic-btn" onclick="toggleRecording()">
      <svg viewBox="0 0 24 24">
        <path d="M12 14c1.66 0 3-1.34 3-3V5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3z"/>
        <path d="M17 11c0 2.76-2.24 5-5 5s-5-2.24-5-5H5c0 3.53 2.61 6.43 6 6.92V21h2v-3.08c3.39-.49 6-3.39 6-6.92h-2z"/>
      </svg>
    </button>
    <div class="question-counter" id="question-counter">Question 1</div>

    <!-- Text Input (hidden) -->
    <div class="text-input-area" id="text-input-area">
      <input type="text" id="text-input" placeholder="Type your answer..." autocomplete="off">
      <button onclick="submitTextAnswer()">Send</button>
    </div>

    <button class="text-mode-toggle" id="text-mode-toggle" onclick="toggleTextMode()">Switch to Text Mode</button>
  </footer>

  <script>
    // ‚ïê‚ïê‚ïê STATE ‚ïê‚ïê‚ïê
    let isRecording = false;
    let isTextMode = false;
    let isProcessing = false;
    let questionNumber = 0;
    let maxQuestions = 8;
    let sessionId = null;
    let mediaRecorder = null;
    let audioChunks = [];
    let audioCtx, analyser, dataArray, bufferLength, canvasCtx, drawVisual;
    let recognition = null;
    let interviewConfig = null;
    let silenceAudioCtx = null;
    let isMuted = false;
    let ttsAudio = document.createElement('audio'); // Persistent element for autoplay
    let recordingStartTime = 0;
    let audioUnlocked = false;

    // ‚ïê‚ïê‚ïê INIT ‚ïê‚ïê‚ïê
    document.addEventListener('DOMContentLoaded', async () => {
      // Load config from session storage
      const raw = sessionStorage.getItem('aiInterviewConfig');
      if (raw) {
        try {
          interviewConfig = JSON.parse(raw);
          document.getElementById('meta-role').textContent = interviewConfig.role;
          document.getElementById('meta-focus').textContent =
            (interviewConfig.focus.charAt(0).toUpperCase() + interviewConfig.focus.slice(1)) +
            ' ¬∑ ' +
            (interviewConfig.difficulty.charAt(0).toUpperCase() + interviewConfig.difficulty.slice(1));
        } catch(e) { console.warn('Config parse error', e); }
      }

      // Setup text input enter key
      document.getElementById('text-input').addEventListener('keydown', (e) => {
        if (e.key === 'Enter') submitTextAnswer();
      });

      // Wait for user tap to unlock audio, then start
      const overlay = document.getElementById('start-overlay');
      overlay.addEventListener('click', async () => {
        // Unlock audio autoplay
        try {
          ttsAudio.src = 'data:audio/wav;base64,UklGRiQAAABXQVZFZm10IBAAAAABAAEARKwAAIhYAQACABAAZGF0YQAAAAA=';
          await ttsAudio.play();
          ttsAudio.pause();
          ttsAudio.currentTime = 0;
          ttsAudio.src = '';
          audioUnlocked = true;
        } catch(e) {}

        overlay.classList.add('hidden');
        setTimeout(() => overlay.remove(), 500);
        await startInterviewSession();
      }, { once: true });
    });


    // ‚ïê‚ïê‚ïê START INTERVIEW SESSION ‚ïê‚ïê‚ïê
    async function startInterviewSession() {
      if (!interviewConfig) {
        setStatus('No config found. Redirecting...', '');
        setTimeout(() => { window.location.href = '/interview'; }, 1500);
        return;
      }

      setStatus('Starting interview...', 'processing');
      const questionEl = document.getElementById('ai-question');
      questionEl.innerHTML = '<span class="typewriter-cursor"></span>';

      try {
        const res = await fetch('/api/interview/start', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            role: interviewConfig.role,
            focus: interviewConfig.focus,
            difficulty: interviewConfig.difficulty
          })
        });

        const contentType = res.headers.get('content-type') || '';

        if (contentType.includes('text/event-stream')) {
          // Streaming response (real AI)
          await handleSSEStream(res, questionEl);
        } else {
          // JSON response (mock AI)
          const data = await res.json();
          sessionId = data.sessionId;
          questionNumber = data.questionNumber || 1;
          updateQuestionCounter();
          typewriterEffect(questionEl, data.question);
          playTTS(data.question);
          setStatus('Tap the mic to answer', '');
        }
      } catch (err) {
        console.error('Failed to start interview:', err);
        setStatus('Failed to connect. Try refreshing.', '');
      }
    }


    // ‚ïê‚ïê‚ïê SSE STREAM HANDLER ‚ïê‚ïê‚ïê
    async function handleSSEStream(response, questionEl) {
      const reader = response.body.getReader();
      const decoder = new TextDecoder();
      let buffer = '';
      let fullText = '';

      // Start typewriter display
      questionEl.classList.remove('fade-in');
      void questionEl.offsetWidth;
      questionEl.classList.add('fade-in');

      while (true) {
        const { done, value } = await reader.read();
        if (done) break;

        buffer += decoder.decode(value, { stream: true });
        const lines = buffer.split('\n');
        buffer = lines.pop(); // keep incomplete line

        for (const line of lines) {
          if (!line.startsWith('data: ')) continue;
          try {
            const data = JSON.parse(line.slice(6));

            if (data.type === 'session') {
              sessionId = data.sessionId;
            } else if (data.type === 'transcript') {
              // Show user's transcribed answer
              showTranscription(data.content);
            } else if (data.type === 'token') {
              fullText += data.content;
              questionEl.innerHTML = fullText + '<span class="typewriter-cursor"></span>';
            } else if (data.type === 'done') {
              questionNumber = data.questionNumber || questionNumber + 1;
              updateQuestionCounter();

              // Remove cursor
              setTimeout(() => { questionEl.innerHTML = fullText; }, 1500);

              // Play TTS for the completed question
              playTTS(fullText);

              if (data.status === 'complete') {
                handleInterviewComplete();
              } else {
                setStatus('Tap the mic to answer', '');
                isProcessing = false;
                // Clear transcription for next round
                setTimeout(() => {
                  document.getElementById('transcription-area').style.display = 'none';
                  document.getElementById('transcription-text').innerHTML = '';
                  document.getElementById('transcription-text').dataset.final = '';
                }, 2000);
              }
            } else if (data.type === 'error') {
              console.error('Stream error:', data.message);
              setStatus('Error generating question. Try again.', '');
              isProcessing = false;
            }
          } catch(e) { /* skip malformed lines */ }
        }
      }
    }


    // ‚ïê‚ïê‚ïê RECORDING TOGGLE ‚ïê‚ïê‚ïê
    async function toggleRecording() {
      if (isProcessing) return;
      // Unlock audio on first user gesture
      if (!audioUnlocked) {
        audioUnlocked = true;
        try {
          ttsAudio.src = 'data:audio/wav;base64,UklGRiQAAABXQVZFZm10IBAAAAABAAEARKwAAIhYAQACABAAZGF0YQAAAAA=';
          await ttsAudio.play();
          ttsAudio.pause();
          ttsAudio.currentTime = 0;
          ttsAudio.src = '';
        } catch(e) {}
      }
      if (isRecording) {
        stopRecording();
      } else {
        await startRecording();
      }
    }

    async function startRecording() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true,
            sampleRate: 16000,
            channelCount: 1
          }
        });

        audioChunks = [];
        const mimeType = MediaRecorder.isTypeSupported('audio/webm;codecs=opus')
          ? 'audio/webm;codecs=opus'
          : MediaRecorder.isTypeSupported('audio/webm')
            ? 'audio/webm'
            : undefined;

        mediaRecorder = new MediaRecorder(stream, mimeType ? { mimeType } : {});
        mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
        mediaRecorder.onstop = onRecordingStop;
        mediaRecorder.start();

        isRecording = true;
        recordingStartTime = Date.now();
        document.getElementById('transcription-text').dataset.final = '';
        updateRecordingUI(true);
        startWaveform(stream);
        startSpeechRecognition();
        startSilenceDetection(stream);

      } catch (err) {
        console.error('Mic access denied:', err);
        setStatus('Microphone access denied', '');
      }
    }

    function stopRecording() {
      if (!isRecording) return;
      isRecording = false;

      if (mediaRecorder && mediaRecorder.state !== 'inactive') {
        mediaRecorder.stop();
        mediaRecorder.stream.getTracks().forEach(t => t.stop());
      }
      if (recognition) {
        try { recognition.stop(); } catch(e) {}
      }
      if (silenceAudioCtx && silenceAudioCtx.state !== 'closed') {
        try { silenceAudioCtx.close(); } catch(e) {}
      }
      stopWaveform();
      updateRecordingUI(false);
    }

    async function onRecordingStop() {
      // Reject recordings shorter than 1.5 seconds
      const recordingDuration = Date.now() - recordingStartTime;
      if (recordingDuration < 1500) {
        console.warn('Recording too short, ignoring');
        setStatus('Recording too short. Try again.', '');
        return;
      }

      isProcessing = true;
      setStatus('Processing your answer...', 'processing');

      // Build audio blob and send to backend
      const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
      const formData = new FormData();
      formData.append('audio', audioBlob, 'interview-answer.webm');
      formData.append('sessionId', sessionId);

      const questionEl = document.getElementById('ai-question');

      try {
        const res = await fetch('/api/interview/respond', {
          method: 'POST',
          body: formData
        });

        const contentType = res.headers.get('content-type') || '';

        if (contentType.includes('text/event-stream')) {
          // Streaming response (real AI)
          questionEl.innerHTML = '<span class="typewriter-cursor"></span>';
          await handleSSEStream(res, questionEl);
        } else {
          // JSON response (mock or complete)
          const data = await res.json();

          if (data.transcript) {
            showTranscription(data.transcript);
          }

          if (data.status === 'complete') {
            handleInterviewComplete();
            return;
          }

          if (data.question) {
            questionNumber = data.questionNumber || questionNumber + 1;
            updateQuestionCounter();
            typewriterEffect(questionEl, data.question);
            playTTS(data.question);
            setStatus('Tap the mic to answer', '');

            setTimeout(() => {
              document.getElementById('transcription-area').style.display = 'none';
              document.getElementById('transcription-text').innerHTML = '';
              document.getElementById('transcription-text').dataset.final = '';
            }, 2000);
          }

          isProcessing = false;
        }
      } catch (err) {
        console.error('Submit error:', err);
        setStatus('Failed to submit. Try again.', '');
        isProcessing = false;
      }
    }


    // ‚ïê‚ïê‚ïê INTERVIEW COMPLETE ‚ïê‚ïê‚ïê
    function handleInterviewComplete() {
      isProcessing = true;
      const micBtn = document.getElementById('mic-btn');
      micBtn.style.opacity = '0.3';
      micBtn.style.pointerEvents = 'none';
      document.getElementById('text-mode-toggle').style.display = 'none';
      document.getElementById('text-input-area').classList.remove('visible');

      setStatus('Interview Complete ‚Äî Generating report...', 'processing');
      document.getElementById('question-counter').textContent = `All ${maxQuestions} questions answered`;

      typewriterEffect(
        document.getElementById('ai-question'),
        'Thank you for completing this interview. Preparing your performance report...'
      );

      // Save sessionId and navigate to report
      sessionStorage.setItem('interviewSessionId', sessionId);
      setTimeout(() => {
        window.location.href = '/interview/report';
      }, 3000);
    }


    // ‚ïê‚ïê‚ïê UI HELPERS ‚ïê‚ïê‚ïê
    function showTranscription(text) {
      document.getElementById('transcription-area').style.display = 'block';
      const words = text.split(' ').filter(Boolean);
      document.getElementById('transcription-text').innerHTML = words.map(w =>
        `<span class="word">${w} </span>`
      ).join('');
    }

    function updateQuestionCounter() {
      document.getElementById('question-counter').textContent = `Question ${questionNumber} of ${maxQuestions}`;
    }

    function updateRecordingUI(recording) {
      const micBtn = document.getElementById('mic-btn');
      const waveContainer = document.getElementById('waveform-container');

      if (recording) {
        micBtn.classList.add('recording');
        waveContainer.classList.add('active');
        setStatus('Listening...', 'listening');
        document.getElementById('transcription-area').style.display = 'block';
      } else {
        micBtn.classList.remove('recording');
        waveContainer.classList.remove('active');
      }
    }

    function setStatus(text, type) {
      const el = document.getElementById('status-text');
      el.className = 'status-text' + (type ? ` ${type}` : '');

      if (type === 'listening' || type === 'processing') {
        el.innerHTML = `${text} <span class="listening-dots"><span></span><span></span><span></span></span>`;
      } else {
        el.textContent = text;
      }
    }


    // ‚ïê‚ïê‚ïê TYPEWRITER EFFECT ‚ïê‚ïê‚ïê
    function typewriterEffect(element, text) {
      element.classList.remove('fade-in');
      element.innerHTML = '<span class="typewriter-cursor"></span>';
      void element.offsetWidth;
      element.classList.add('fade-in');

      let i = 0;
      const speed = 30;

      function type() {
        if (i < text.length) {
          element.innerHTML = text.substring(0, i + 1) + '<span class="typewriter-cursor"></span>';
          i++;
          setTimeout(type, speed);
        } else {
          setTimeout(() => { element.innerHTML = text; }, 1500);
        }
      }
      type();
    }


    // ‚ïê‚ïê‚ïê SPEECH RECOGNITION (Live Transcription) ‚ïê‚ïê‚ïê
    function startSpeechRecognition() {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      if (!SpeechRecognition) return;

      recognition = new SpeechRecognition();
      recognition.continuous = true;
      recognition.interimResults = true;
      recognition.lang = 'en-US';

      const transcriptionEl = document.getElementById('transcription-text');

      recognition.onresult = (event) => {
        let finalTranscript = '';
        let interimTranscript = '';

        for (let i = event.resultIndex; i < event.results.length; i++) {
          const transcript = event.results[i][0].transcript;
          if (event.results[i].isFinal) {
            finalTranscript += transcript;
          } else {
            interimTranscript += transcript;
          }
        }

        const fullText = (transcriptionEl.dataset.final || '') + finalTranscript;
        transcriptionEl.dataset.final = fullText;

        const words = (fullText + interimTranscript).split(' ').filter(Boolean);
        transcriptionEl.innerHTML = words.map(w =>
          `<span class="word">${w} </span>`
        ).join('');
      };

      recognition.onerror = (e) => {
        console.warn('Speech recognition error:', e.error);
      };

      recognition.onend = () => {
        if (isRecording) {
          try { recognition.start(); } catch(e) {}
        }
      };

      try { recognition.start(); } catch(e) {}
    }


    // ‚ïê‚ïê‚ïê SILENCE DETECTION ‚ïê‚ïê‚ïê
    function startSilenceDetection(stream) {
      silenceAudioCtx = new (window.AudioContext || window.webkitAudioContext)();
      const source = silenceAudioCtx.createMediaStreamSource(stream);
      const detector = silenceAudioCtx.createAnalyser();
      source.connect(detector);
      detector.fftSize = 512;
      const bufLen = detector.frequencyBinCount;
      const data = new Uint8Array(bufLen);

      let silenceStart = null;
      const SILENCE_THRESHOLD = 10;
      const SILENCE_DURATION = 4000;   // 4 seconds of silence to auto-stop
      const GRACE_PERIOD = 5000;       // Don't check silence for first 5 seconds
      const recordingStart = Date.now();

      function checkSilence() {
        if (!isRecording) return;

        // Don't check silence during grace period
        if (Date.now() - recordingStart < GRACE_PERIOD) {
          requestAnimationFrame(checkSilence);
          return;
        }

        detector.getByteFrequencyData(data);
        const avg = data.reduce((sum, v) => sum + v, 0) / bufLen;

        if (avg < SILENCE_THRESHOLD) {
          if (!silenceStart) silenceStart = Date.now();
          else if (Date.now() - silenceStart > SILENCE_DURATION) {
            stopRecording();
            return;
          }
        } else {
          silenceStart = null;
        }

        requestAnimationFrame(checkSilence);
      }
      checkSilence();
    }


    // ‚ïê‚ïê‚ïê WAVEFORM VISUALIZATION ‚ïê‚ïê‚ïê
    function startWaveform(stream) {
      const canvas = document.getElementById('waveform-canvas');
      const container = document.getElementById('waveform-container');
      canvas.width = container.offsetWidth * 2;
      canvas.height = container.offsetHeight * 2;
      canvasCtx = canvas.getContext('2d');

      audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      analyser = audioCtx.createAnalyser();
      const source = audioCtx.createMediaStreamSource(stream);
      source.connect(analyser);
      analyser.fftSize = 128;
      bufferLength = analyser.frequencyBinCount;
      dataArray = new Uint8Array(bufferLength);

      drawWaveform();
    }

    function drawWaveform() {
      if (!isRecording) return;
      drawVisual = requestAnimationFrame(drawWaveform);

      analyser.getByteFrequencyData(dataArray);

      const w = canvasCtx.canvas.width;
      const h = canvasCtx.canvas.height;
      canvasCtx.clearRect(0, 0, w, h);

      const barWidth = (w / bufferLength) * 1.5;
      const gap = 2;
      let x = (w - (barWidth + gap) * bufferLength) / 2;

      for (let i = 0; i < bufferLength; i++) {
        const v = dataArray[i] / 255;
        const barHeight = Math.max(v * h * 0.8, 2);

        const gradient = canvasCtx.createLinearGradient(0, h / 2 - barHeight / 2, 0, h / 2 + barHeight / 2);
        gradient.addColorStop(0, 'rgba(14, 165, 233, 0.9)');
        gradient.addColorStop(1, 'rgba(14, 165, 233, 0.3)');
        canvasCtx.fillStyle = gradient;

        canvasCtx.beginPath();
        canvasCtx.roundRect(x, h / 2 - barHeight / 2, barWidth, barHeight, 2);
        canvasCtx.fill();

        x += barWidth + gap;
      }
    }

    function stopWaveform() {
      if (drawVisual) cancelAnimationFrame(drawVisual);
      if (audioCtx && audioCtx.state !== 'closed') {
        try { audioCtx.close(); } catch(e) {}
      }
    }


    // ‚ïê‚ïê‚ïê TEXT MODE ‚ïê‚ïê‚ïê
    function toggleTextMode() {
      if (isProcessing) return;
      isTextMode = !isTextMode;
      const textArea = document.getElementById('text-input-area');
      const micBtn = document.getElementById('mic-btn');
      const toggle = document.getElementById('text-mode-toggle');

      if (isTextMode) {
        textArea.classList.add('visible');
        micBtn.style.display = 'none';
        toggle.textContent = 'Switch to Voice Mode';
        document.getElementById('text-input').focus();
      } else {
        textArea.classList.remove('visible');
        micBtn.style.display = 'flex';
        toggle.textContent = 'Switch to Text Mode';
      }
    }

    async function submitTextAnswer() {
      const input = document.getElementById('text-input');
      const answer = input.value.trim();
      if (!answer || isProcessing) return;

      input.value = '';
      isProcessing = true;
      showTranscription(answer);
      setStatus('Processing your answer...', 'processing');

      // For text mode, we still need to send audio ‚Äî but we can create a silent blob
      // and pass the text as a workaround. For now, create a tiny silent audio blob.
      // In production we'd add a text-only endpoint.
      const questionEl = document.getElementById('ai-question');

      try {
        // Create a minimal silent audio blob
        const sampleRate = 16000;
        const numSamples = sampleRate * 0.1;
        const audioBuffer = new ArrayBuffer(44 + numSamples * 2);
        const view = new DataView(audioBuffer);
        // WAV header
        const writeString = (offset, str) => { for(let i=0;i<str.length;i++) view.setUint8(offset+i, str.charCodeAt(i)); };
        writeString(0, 'RIFF');
        view.setUint32(4, 36 + numSamples * 2, true);
        writeString(8, 'WAVE');
        writeString(12, 'fmt ');
        view.setUint32(16, 16, true);
        view.setUint16(20, 1, true);
        view.setUint16(22, 1, true);
        view.setUint32(24, sampleRate, true);
        view.setUint32(28, sampleRate * 2, true);
        view.setUint16(32, 2, true);
        view.setUint16(34, 16, true);
        writeString(36, 'data');
        view.setUint32(40, numSamples * 2, true);

        const audioBlob = new Blob([audioBuffer], { type: 'audio/wav' });

        const formData = new FormData();
        formData.append('audio', audioBlob, 'text-answer.wav');
        formData.append('sessionId', sessionId);

        const res = await fetch('/api/interview/respond', {
          method: 'POST',
          body: formData
        });

        const contentType = res.headers.get('content-type') || '';

        if (contentType.includes('text/event-stream')) {
          questionEl.innerHTML = '<span class="typewriter-cursor"></span>';
          await handleSSEStream(res, questionEl);
        } else {
          const data = await res.json();

          if (data.status === 'complete') {
            handleInterviewComplete();
            return;
          }

          if (data.question) {
            questionNumber = data.questionNumber || questionNumber + 1;
            updateQuestionCounter();
            typewriterEffect(questionEl, data.question);
            setStatus(isTextMode ? 'Type your answer' : 'Tap the mic to answer', '');

            setTimeout(() => {
              document.getElementById('transcription-area').style.display = 'none';
              document.getElementById('transcription-text').innerHTML = '';
              document.getElementById('transcription-text').dataset.final = '';
            }, 2000);
          }

          isProcessing = false;
        }
      } catch (err) {
        console.error('Text submit error:', err);
        setStatus('Failed to submit. Try again.', '');
        isProcessing = false;
      }
    }


    // ‚ïê‚ïê‚ïê TTS PLAYBACK ‚ïê‚ïê‚ïê
    async function playTTS(text) {
      if (isMuted || !text || !text.trim()) return;

      const indicator = document.getElementById('tts-indicator');
      indicator.classList.add('active');
      indicator.querySelector('span').textContent = 'Generating voice...';

      try {
        const res = await fetch('/api/interview/tts', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ text: text.trim() })
        });

        const contentType = res.headers.get('content-type') || '';

        if (contentType.includes('application/json') || !res.ok) {
          indicator.classList.remove('active');
          return;
        }

        const audioBlob = await res.blob();

        if (audioBlob.size < 100) {
          indicator.classList.remove('active');
          return;
        }

        // Pause speech recognition so mic doesn't pick up AI voice
        if (recognition) {
          try { recognition.abort(); } catch(e) {}
        }

        // Revoke previous URL if any
        if (ttsAudio._blobUrl) {
          URL.revokeObjectURL(ttsAudio._blobUrl);
        }

        const audioUrl = URL.createObjectURL(audioBlob);
        ttsAudio._blobUrl = audioUrl;

        // Use persistent audio element ‚Äî just change src
        ttsAudio.onended = () => {
          indicator.classList.remove('active');
          if (ttsAudio._blobUrl) {
            URL.revokeObjectURL(ttsAudio._blobUrl);
            ttsAudio._blobUrl = null;
          }
        };
        ttsAudio.onerror = () => {
          indicator.classList.remove('active');
        };

        ttsAudio.src = audioUrl;
        indicator.querySelector('span').textContent = 'Speaking...';
        await ttsAudio.play();

      } catch (err) {
        console.warn('[TTS] Error:', err.message);
        indicator.classList.remove('active');
      }
    }

    function toggleMute() {
      isMuted = !isMuted;
      const btn = document.getElementById('btn-mute');
      if (isMuted) {
        btn.textContent = 'üîá Muted';
        btn.classList.add('muted');
        // Stop current audio
        ttsAudio.pause();
        ttsAudio.src = '';
        document.getElementById('tts-indicator').classList.remove('active');
      } else {
        btn.textContent = 'üîä Voice';
        btn.classList.remove('muted');
      }
    }


    // ‚ïê‚ïê‚ïê END INTERVIEW ‚ïê‚ïê‚ïê
    function endInterview() {
      if (isRecording) stopRecording();
      ttsAudio.pause();
      ttsAudio.src = '';
      if (confirm('End this interview and view your report?')) {
        sessionStorage.setItem('interviewSessionId', sessionId);
        window.location.href = '/interview/report';
      }
    }
  </script>
</body>
</html>
